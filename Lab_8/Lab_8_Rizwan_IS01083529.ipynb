{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1e8747d2-6a25-4d05-9689-33ca3a19f556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tabulate import tabulate\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cfefb416-fb88-438f-971c-4b3fe8162541",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [\"I love playing football on the weekends\",\n",
    "           \"I enjoy hiking and camping in the mountains\",\n",
    "           \"I like to read books and watch movies\",\n",
    "           \"I prefer playing video games over sports\",\n",
    "           \"I love listening to music and going to concerts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9ba76772-e6ab-4fbe-8a3c-d6aa582a4f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "51b4890d-52bc-4497-85b2-ca34a9785a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document                                           Predicted Cluster\n",
      "-----------------------------------------------  -------------------\n",
      "I love playing football on the weekends                            1\n",
      "I enjoy hiking and camping in the mountains                        1\n",
      "I like to read books and watch movies                              0\n",
      "I prefer playing video games over sports                           1\n",
      "I love listening to music and going to concerts                    0\n",
      "\n",
      "Top terms per cluster:\n",
      "Cluster 0:\n",
      " to\n",
      "\n",
      " and\n",
      "\n",
      " read\n",
      "\n",
      " watch\n",
      "\n",
      " movies\n",
      "\n",
      " like\n",
      "\n",
      " books\n",
      "\n",
      " concerts\n",
      "\n",
      " going\n",
      "\n",
      " music\n",
      "\n",
      "Cluster 1:\n",
      " playing\n",
      "\n",
      " the\n",
      "\n",
      " weekends\n",
      "\n",
      " on\n",
      "\n",
      " football\n",
      "\n",
      " video\n",
      "\n",
      " sports\n",
      "\n",
      " prefer\n",
      "\n",
      " over\n",
      "\n",
      " games\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = 2 # Define the number of clusters\n",
    "km = KMeans(n_clusters=k)\n",
    "km.fit(X)\n",
    "\n",
    "# Predict the clusters for each document\n",
    "y_pred = km.predict(X)\n",
    "\n",
    "# Display the document and its predicted cluster in a table\n",
    "table_data = [[\"Document\", \"Predicted Cluster\"]]\n",
    "table_data.extend([[doc, cluster] for doc, cluster in zip(dataset, y_pred)])\n",
    "print(tabulate(table_data, headers=\"firstrow\"))\n",
    "print(\"\\nTop terms per cluster:\")\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "for i in range(k):\n",
    "    print(\"Cluster %d:\" % i)\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9dd0211a-2933-45ca-b3eb-3604b470154f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity: 0.6\n"
     ]
    }
   ],
   "source": [
    "# Calculate purity\n",
    "total_samples = len(y_pred)\n",
    "cluster_label_counts = [Counter(y_pred)]\n",
    "purity = sum(max(cluster.values()) for cluster in cluster_label_counts) / total_samples\n",
    "print(\"Purity:\", purity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b002e741-0bf5-4b8d-b411-ac171d352d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from gensim.models import Word2Vec\n",
    "from tabulate import tabulate\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3fa86b93-50cf-47d4-b320-9790eaf84dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [\"I love playing football on the weekends\",\n",
    "           \"I enjoy hiking and camping in the mountains\",\n",
    "           \"I like to read books and watch movies\",\n",
    "           \"I prefer playing video games over sports\",\n",
    "           \"I love listening to music and going to concerts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "174d27d4-f0fe-44ac-a914-ee8173a25dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = [doc.split() for doc in dataset]\n",
    "word2vec_model = Word2Vec(sentences=tokenized_dataset, vector_size=100,window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d32663fd-b57c-4384-bb26-369089dc2c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([np.mean([word2vec_model.wv[word] for word in doc.split() if word in \n",
    "word2vec_model.wv], axis=0) for doc in dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9d6bcea6-955c-4026-91e8-2cfa317ee90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document                                           Predicted Cluster\n",
      "-----------------------------------------------  -------------------\n",
      "I love playing football on the weekends                            1\n",
      "I enjoy hiking and camping in the mountains                        1\n",
      "I like to read books and watch movies                              0\n",
      "I prefer playing video games over sports                           1\n",
      "I love listening to music and going to concerts                    0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AnacondaNavigator\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "k = 2 # Define the number of clusters\n",
    "km = KMeans(n_clusters=k)\n",
    "km.fit(X)\n",
    "\n",
    "# Predict the clusters for each document\n",
    "y_pred = km.predict(X)\n",
    "\n",
    "# Tabulate the document and predicted cluster\n",
    "table_data = [[\"Document\", \"Predicted Cluster\"]]\n",
    "table_data.extend([[doc, cluster] for doc, cluster in zip(dataset, y_pred)])\n",
    "print(tabulate(table_data, headers=\"firstrow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e373e664-12bf-44c5-bb8a-c7174812de0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity: 0.6\n"
     ]
    }
   ],
   "source": [
    "# Calculate purity\n",
    "total_samples = len(y_pred)\n",
    "cluster_label_counts = [Counter(y_pred)]\n",
    "purity = sum(max(cluster.values()) for cluster in cluster_label_counts) / total_samples\n",
    "print(\"Purity:\", purity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "01c64703-bf04-4ba8-9888-3a8f728ae538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec Clustering Results:\n",
      "\n",
      "Document                                                           Predicted Cluster\n",
      "---------------------------------------------------------------  -------------------\n",
      "I used to love Comcast. Until all these constant updates. My...                    0\n",
      "I'm so over Comcast! The worst internet provider. I'm taking...                    2\n",
      "If I could give them a negative star or no stars on this rev...                    0\n",
      "I've had the worst experiences so far since install on 10/4/...                    0\n",
      "Check your contract when you sign up for Comcast as their ad...                    0\n",
      "Thank God. I am changing to Dish. They gave me awesome prici...                    0\n",
      "I Have been a long time customer and only have Xfinity as my...                    1\n",
      "There is a malfunction on the DVR manager which is preventin...                    0\n",
      "Charges overwhelming. Comcast service rep was so ignorant an...                    1\n",
      "\n",
      "Purity: 0.5263157894736842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\AnacondaNavigator\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from collections import Counter\n",
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"customer_complaints_1.csv\")\n",
    "\n",
    "# Preprocessing for Word2Vec\n",
    "def preprocess_and_tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", text)\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    tokens = text.strip().split()\n",
    "    return tokens\n",
    "\n",
    "df['tokens'] = df['text'].astype(str).apply(preprocess_and_tokenize)\n",
    "\n",
    "# Train Word2Vec model\n",
    "w2v_model = Word2Vec(sentences=df['tokens'], vector_size=100, window=5, min_count=1, workers=4, sg=1, seed=42)\n",
    "\n",
    "# Average word vectors for each document\n",
    "def average_word_vector(tokens, model, vector_size):\n",
    "    valid_tokens = [token for token in tokens if token in model.wv]\n",
    "    if not valid_tokens:\n",
    "        return np.zeros(vector_size)\n",
    "    return np.mean([model.wv[token] for token in valid_tokens], axis=0)\n",
    "\n",
    "vector_size = 100\n",
    "X_w2v = np.array([average_word_vector(tokens, w2v_model, vector_size) for tokens in df['tokens']])\n",
    "\n",
    "# KMeans clustering\n",
    "k = 3\n",
    "km_w2v = KMeans(n_clusters=k, random_state=42)\n",
    "y_pred_w2v = km_w2v.fit_predict(X_w2v)\n",
    "\n",
    "# Show first 10 results\n",
    "print(\"Word2Vec Clustering Results:\\n\")\n",
    "table_data = [[\"Document\", \"Predicted Cluster\"]]\n",
    "table_data.extend([[doc[:60] + \"...\", cluster] for doc, cluster in zip(df['text'], y_pred_w2v)])\n",
    "print(tabulate(table_data[:10], headers=\"firstrow\"))\n",
    "\n",
    "# Mock purity (based on majority class size)\n",
    "cluster_counts = Counter(y_pred_w2v)\n",
    "purity = max(cluster_counts.values()) / len(y_pred_w2v)\n",
    "print(\"\\nPurity:\", purity)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
